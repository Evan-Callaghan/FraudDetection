{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b9acd94-06b8-4191-8745-9467e3136cc4",
   "metadata": {},
   "source": [
    "## Initial exploratory analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d31d0eab-ddd7-48ee-a88a-5b9d0369afc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/lib/arraysetops.py:583: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "## importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopy.distance \n",
    "from dateutil.relativedelta import relativedelta\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "## Here we set the directory to look up the folder containing the data\n",
    "os.chdir(\"/Users/gabrielmedeiros/Documents/OneDrive/Business analytics/DATA_445_Machine_Learning\")\n",
    "\n",
    "\n",
    "## Reading csv file, index_col = 0 makes the first column of the data to become the index of our pandas data frame\n",
    "test_data = pd.read_csv('fraudTest.csv', index_col = 0)\n",
    "\n",
    "train_data = pd.read_csv('fraudTrain.csv', index_col = 0)\n",
    "\n",
    "n = test_data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccadbe00-2112-40ba-a67b-c43dc6d9db80",
   "metadata": {},
   "source": [
    "## Head of Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047ffe1a-3ea7-4a0e-808d-0249f166de3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data.shape)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1eb5ed-b259-4251-a667-f5fe9e1dd692",
   "metadata": {},
   "source": [
    "## Head of Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286b7a92-d1b3-414c-bbe6-3d97fccce467",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_data.shape)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92595e5a-8174-491e-acb3-f4649ffbcbfe",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fecd077-8821-4841-a5ce-8b4e17a7a54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##############\n",
    "## Distance ##\n",
    "##############\n",
    "\n",
    "\n",
    "## Here assign to n the amount of observations we have in the dataset\n",
    "n = test_data.shape[0]\n",
    "\n",
    "## Creating empty list to store the reuslts\n",
    "distance_to_append = []\n",
    "\n",
    "## Looping through each row an computing the distance between ?????????\n",
    "for i in range(0,n):\n",
    "    \n",
    "    ## Here we gather the lat and long from the ?????\n",
    "    coords_1 = (test_data['lat'][i], test_data['long'][i])\n",
    "    \n",
    "    ## Here we gather the lat and long from the ?????\n",
    "    coords_2 = (test_data['merch_lat'][i], test_data['merch_long'][i])\n",
    "    \n",
    "    ## Here we compute the disance in miles between the locations\n",
    "    distance_to_append.append(geopy.distance.geodesic(coords_1, coords_2).miles)\n",
    "\n",
    "## Adding results to our data set\n",
    "test_data['Distance'] = distance_to_append\n",
    "\n",
    "\n",
    "##################\n",
    "## AVG Distance ##\n",
    "##################\n",
    "\n",
    "## Here we create a groupby function to get the mean distance by each category\n",
    "avg_dist_by_category = pd.DataFrame(test_data.groupby(['cc_num','category'])['Distance'].mean())\n",
    "\n",
    "## Here we create a temporary column holding our index values (cc_num)\n",
    "avg_dist_by_category['columns'] = avg_dist_by_category.index\n",
    "\n",
    "## Here we drop our temporary column and reset our index, which was previously our cc_num\n",
    "avg_dist_by_category = avg_dist_by_category.reset_index().drop(columns = 'columns')\n",
    "\n",
    "## Here we rename the columns of the groupby function\n",
    "avg_dist_by_category.columns = ['cc_num','category','avg_distance_by_category']\n",
    "\n",
    "## Here we merge our temporary data frame with our data set\n",
    "test_data = avg_dist_by_category.merge(test_data, on = ['cc_num','category'], how = 'left')\n",
    "\n",
    "\n",
    "#############################\n",
    "## AVG Distance by Category##\n",
    "#############################\n",
    "\n",
    "## Here we create a groupby function to get the mean distance by each category\n",
    "avg_dist = pd.DataFrame(test_data.groupby(['cc_num'])['Distance'].mean())\n",
    "\n",
    "## Here we create a temporary column holding our index values (cc_num)\n",
    "avg_dist['columns'] = avg_dist.index\n",
    "\n",
    "## Here we drop our temporary column and reset our index, which was previously our cc_num\n",
    "avg_dist = avg_dist.reset_index().drop(columns = 'columns')\n",
    "\n",
    "## Here we rename the columns of the groupby function\n",
    "avg_dist.columns = ['cc_num','avg_distance']\n",
    "\n",
    "## Here we merge our temporary data frame with our data set\n",
    "test_data = avg_dist.merge(test_data, on = ['cc_num'], how = 'left')\n",
    "\n",
    "#########\n",
    "## Age ##\n",
    "#########\n",
    "\n",
    "## Creating empty list to store the resutls\n",
    "ages_to_append = []\n",
    "\n",
    "## Looping through each observation and computing the age of each individual from its DOB\n",
    "for i in range(0,n):\n",
    "    \n",
    "    ## Here we add the last date of this year\n",
    "    year_of_2021 = datetime.strptime('2021-12-31', \"%Y-%m-%d\")\n",
    "    \n",
    "    ## Here we call each DOB in the dataset\n",
    "    dob = datetime.strptime(test_data.dob[i], \"%Y-%m-%d\")\n",
    "    \n",
    "    ## Here we compute the ages\n",
    "    ages_to_append.append(relativedelta(year_of_2021, dob).years)\n",
    "\n",
    "## Adding results to our data set\n",
    "test_data['Age'] = ages_to_append\n",
    "\n",
    "######################\n",
    "## Days of the Week ##\n",
    "######################\n",
    "\n",
    "## Here we change the format of our date column\n",
    "dates = pd.to_datetime(test_data['trans_date_trans_time'])\n",
    "\n",
    "## Here we use our library to get the day of the week based on the transformed column\n",
    "test_data['DayOfWeek'] = dates.dt.day_name()\n",
    "\n",
    "#######################\n",
    "## Month of the year ##\n",
    "#######################\n",
    "\n",
    "## Here we change the format of our date column\n",
    "months = pd.to_datetime(test_data['trans_date_trans_time'])\n",
    "\n",
    "## Here we use our library to get the month of the year based on the transformed column\n",
    "test_data['Month'] = dates.dt.month\n",
    "\n",
    "#####################\n",
    "## Hour of the day ##\n",
    "#####################\n",
    "\n",
    "## Here we change the format of our date column\n",
    "hour_of_the_day = []\n",
    "\n",
    "## Here we loop throough each observation, change the format of the items in each column, \n",
    "## and retrieve the hour of the day\n",
    "for i in range(0,n):\n",
    "    hour_of_the_day.append(datetime.strptime(test_data.trans_date_trans_time[i] ,\"%Y-%m-%d %H:%M:%S\").hour)\n",
    "    \n",
    "## Here we attribute our results to a column\n",
    "test_data['HourOfTheDay'] = hour_of_the_day\n",
    "\n",
    "#################################\n",
    "## Total card uses by customer ##\n",
    "#################################\n",
    "\n",
    "## Here we get the number of transactions shown in the data set per card\n",
    "Uses = pd.DataFrame(test_data['cc_num'].value_counts())\n",
    "\n",
    "## Here we create a column to keep our cc_num\n",
    "Uses['cc_number2'] = Uses.index\n",
    "\n",
    "## Here we reset our index\n",
    "Uses = Uses.reset_index(drop = True)\n",
    "\n",
    "## Here we rename our columns\n",
    "Uses.columns = ['TotalUses','cc_num']\n",
    "\n",
    "\n",
    "## Here we merge our temporary data frame with our data set\n",
    "test_data = Uses.merge(test_data, on = 'cc_num', how = 'left')\n",
    "\n",
    "####################################################\n",
    "## Difference in minutes between each transaction ##\n",
    "####################################################\n",
    "\n",
    "## Here we create a list to hold our results\n",
    "new_time = []\n",
    "\n",
    "## Here we loop through each observation and transform the format of our data\n",
    "for i in range(0,n):\n",
    "    new_time.append(datetime.strptime(test_data.trans_date_trans_time[i] ,\"%Y-%m-%d %H:%M:%S\"))\n",
    "    \n",
    "## Here we create a column containing transformed data to compute the difference in minutes\n",
    "## New format was recquired for the library to work\n",
    "test_data['transformed_time'] = new_time\n",
    "\n",
    "## Here we compute the difference in minutes between each transacion\n",
    "test_data['DiffByCardTrans'] = test_data.groupby('cc_num')\\\n",
    "                               ['transformed_time'].diff().apply(lambda x: \\\n",
    "                               x/np.timedelta64(1, 'm')).fillna(0).astype('int64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4d222fd-ea0b-4217-af5d-29dd4651d406",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here we create a list to hold our results\n",
    "new_time = []\n",
    "\n",
    "n = test_data.shape[0]\n",
    "## Here we loop through each observation and transform the format of our data\n",
    "for i in range(0,n):\n",
    "    new_time.append(datetime.strptime(test_data.trans_date_trans_time[i] ,\"%Y-%m-%d %H:%M:%S\"))\n",
    "    \n",
    "## Here we create a column containing transformed data to compute the difference in minutes\n",
    "## New format was recquired for the library to work\n",
    "test_data['transformed_time'] = new_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428b0407-ccba-497d-a2cc-51606a89fbd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c87322fd-58f5-4aa9-a2ec-8a4f1dbe5588",
   "metadata": {},
   "source": [
    "## Difference in time by minutes for each card in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547669f1-3158-4bf3-af22-460249cb6553",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a9dc61aa-49b7-486d-b9ab-3033a0f81e35",
   "metadata": {},
   "source": [
    "## Average amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fab15b-21c6-4b76-9eab-d0dcd98c23a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "amt_per_category = pd.DataFrame(test_data.groupby(['cc_num','category'])['amt'].mean())\n",
    "\n",
    "amt_per_category['columns'] = amt_per_category.index\n",
    "\n",
    "amt_per_category = amt_per_category.reset_index().drop(columns = 'columns')\n",
    "\n",
    "amt_per_category.columns = ['cc_num','category','avg_by_category']\n",
    "\n",
    "test_data = amt_per_category.merge(test_data, on = ['cc_num','category'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0481eb2c-e67a-47fb-b191-3627df22ecda",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_amt = pd.DataFrame(test_data.groupby('cc_num')['amt'].mean())\n",
    "\n",
    "avg_amt['columns'] = avg_amt.index\n",
    "\n",
    "avg_amt = avg_amt.reset_index().drop(columns = 'columns')\n",
    "\n",
    "avg_amt.columns = ['cc_num', 'avg_amt']\n",
    "\n",
    "test_data = avg_amt.merge(test_data, on = 'cc_num', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87446f6-41e0-4838-9c4e-1945a32386c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375c245c-df49-4fee-b9d1-0e5d73403df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['purchase_>_avg'] = np.where(test_data['amt'] > test_data['avg_amt'],1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfdf86b-bd0c-47cb-9667-c587522b464c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['purchase_>_avg_by_category'] = np.where(test_data['amt'] > test_data['avg_by_category'],1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e8e089-b75d-4af2-b18f-4758bd47f38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['purchase_>_distance'] = np.where(test_data['Distance'] > test_data['avg_distance'],1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b3d660-91ed-45bf-acf3-78ed1e10af33",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['purchase_>_distance_by_category'] = np.where(test_data['Distance'] > test_data['avg_distance_by_category'],1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b5daa7-a0be-43cc-827b-80756e325bc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "temp_cc_time_max = pd.DataFrame(test_data.groupby('cc_num')['trans_date_trans_time'].max())\n",
    "temp_cc_time_min = pd.DataFrame(test_data.groupby('cc_num')['trans_date_trans_time'].min())\n",
    "\n",
    "\n",
    "\n",
    "temp_cc_time_max['columns'] = temp_cc_time_max.index\n",
    "temp_cc_time_min['columns'] = temp_cc_time_min.index\n",
    "\n",
    "temp_cc_time_max = temp_cc_time_max.reset_index().drop(columns = 'columns')\n",
    "temp_cc_time_min = temp_cc_time_min.reset_index().drop(columns = 'columns')\n",
    "\n",
    "\n",
    "temp_cc_time_max.columns = ['cc_num','max_date']\n",
    "temp_cc_time_min.columns = ['cc_num','min_date']\n",
    "\n",
    "\n",
    "test_data = temp_cc_time_max.merge(test_data, on = 'cc_num', how = 'left')\n",
    "test_data = temp_cc_time_min.merge(test_data, on = 'cc_num', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4baec54c-5ee8-48c5-8753-1461f47d397b",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_dates = pd.to_datetime(test_data.min_date) \n",
    "max_dates = pd.to_datetime(test_data.max_date)\n",
    "\n",
    "diff_in_time = max_dates - min_dates\n",
    " \n",
    "temp_data = pd.DataFrame(diff_in_time)\n",
    " \n",
    "test_data['diff_first_last'] = temp_data.apply(lambda x: x/np.timedelta64(1, 'm')).fillna(0).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df81adf-144f-4622-847b-fe06819326b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['diff_first_last'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbd19be-1e6b-468e-8464-d946ef092423",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here we export the file containing all of the new feature to a csv file. \n",
    "#test_data.to_csv (\"/Users/gabrielmedeiros/Documents/OneDrive/Business analytics/DATA_445_Machine_Learning/FraudTestData.csv\", index = None, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
